
# Waifu AI - PTIT Ami Virtual Assistant

<div align="center">
  <img src="public/ptit.png" alt="PTIT Ami" width="200" height="200"/>
  
  **An interactive AI-powered virtual assistant featuring a Live2D character with advanced chat capabilities**
  
  [![Next.js](https://img.shields.io/badge/Next.js-14.2.32-black?style=flat-square&logo=next.js)](https://nextjs.org/)
  [![TypeScript](https://img.shields.io/badge/TypeScript-5.9.2-blue?style=flat-square&logo=typescript)](https://www.typescriptlang.org/)
  [![Live2D](https://img.shields.io/badge/Live2D-Cubism-4.0-orange?style=flat-square)](https://www.live2d.com/)
  [![pnpm](https://img.shields.io/badge/pnpm-9.2.0-pink?style=flat-square&logo=pnpm)](https://pnpm.io/)
</div>

## ğŸŒŸ Features

### ğŸ¤– AI-Powered Chat
- **Gemini AI Integration**: Advanced conversational AI using Google's Gemini 2.5 Flash model
- **Vietnamese Language Support**: Native Vietnamese conversation with PTIT Ami character
- **Sentiment Analysis**: Dynamic emotional responses based on message content
- **Fallback System**: Robust error handling with multiple AI model fallbacks

### ğŸ­ Live2D Character - PTIT Ami
- **16 Unique Expressions**: From happy to sad, including special toggles (glasses, jacket)
- **11 Motion Groups**: Idle animations, greetings, hitbox responses, and special interactions
- **Advanced Hitbox System**: 5 distinct interaction areas (hair, face, head, upper body, body)
- **Real-time Lip Sync**: Mouth animation during speech synthesis
- **Drag & Zoom**: Interactive model positioning with persistent storage
- **Mobile Support**: Touch gestures, pinch-to-zoom, and responsive design

### ğŸµ Voice Synthesis
- **ElevenLabs Integration**: High-quality text-to-speech conversion
- **Custom Voice Support**: Configurable voice ID for personalized experience
- **Real-time Audio**: Synchronized speech with Live2D animations

### ğŸ¨ Multiple Interfaces
- **Full Demo Page**: Complete interactive experience
- **Embeddable Widget**: Customizable widget for integration
- **Theme Support**: Default, dark, and minimal themes
- **Responsive Design**: Works on desktop, tablet, and mobile devices

## ğŸš€ Quick Start

### Prerequisites
- **Node.js** (v18 or higher)
- **pnpm** (v9.2.0 or higher)
- **API Keys** (see Configuration section)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/Nguyenhieu277/Waifu-AI-Dev.git
   cd Waifu-AI-Dev
   ```

2. **Install dependencies**
   ```bash
   pnpm install
   ```

3. **Configure environment variables**
   ```bash
   cp env.example .env.local
   ```
   
   Edit `.env.local` with your API keys:
   ```env
   GEMINI_API_KEY=your_gemini_api_key_here
   ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
   VOICE_ID=EXAVITQu4vr4xnSDxMaL
   NODE_ENV=development
   ```

4. **Run the development server**
   ```bash
   pnpm dev
   ```

5. **Open your browser**
   - Demo: [http://localhost:3000](http://localhost:3000)
   - Widget: [http://localhost:3000/widget](http://localhost:3000/widget)

## ğŸ”§ Configuration

### API Keys Setup

#### Gemini AI (Required)
1. Visit [Google AI Studio](https://aistudio.google.com/app/apikey)
2. Create a new API key
3. Add to `.env.local` as `GEMINI_API_KEY`

#### ElevenLabs (Required for Voice)
1. Sign up at [ElevenLabs](https://elevenlabs.io/speech-synthesis)
2. Get your API key from the dashboard
3. Add to `.env.local` as `ELEVENLABS_API_KEY`
4. Optionally change `VOICE_ID` to your preferred voice

### Widget Configuration

The embeddable widget supports URL parameters:

```
/widget?theme=dark&size=large&position=bottom-right&showBackground=false
```

**Parameters:**
- `theme`: `default` | `dark` | `minimal`
- `size`: `small` | `medium` | `large`
- `position`: `bottom-right` | `bottom-left` | `center`
- `showBackground`: `true` | `false`

## ğŸ“ Project Structure

```
Waifu-AI-Dev/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/                    # Next.js App Router
â”‚   â”‚   â”œâ”€â”€ api/               # API Routes
â”‚   â”‚   â”‚   â”œâ”€â”€ chat/          # Gemini AI chat endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ speech-to-text/ # Speech recognition
â”‚   â”‚   â”‚   â”œâ”€â”€ synthasize/    # Text-to-speech
â”‚   â”‚   â”‚   â””â”€â”€ widget/        # Widget configuration
â”‚   â”‚   â”œâ”€â”€ demo/              # Demo page
â”‚   â”‚   â”œâ”€â”€ widget/            # Widget page
â”‚   â”‚   â””â”€â”€ page.tsx           # Main page
â”‚   â”œâ”€â”€ components/            # React Components
â”‚   â”‚   â”œâ”€â”€ Model.tsx          # Live2D Model (main character)
â”‚   â”‚   â”œâ”€â”€ ChatterBox.tsx     # Chat interface
â”‚   â”‚   â”œâ”€â”€ ChatInput.tsx      # Input component
â”‚   â”‚   â”œâ”€â”€ Widget.tsx         # Embeddable widget
â”‚   â”‚   â””â”€â”€ SimpleWatermark.tsx # Watermark component
â”‚   â”œâ”€â”€ atoms/                 # Jotai state management
â”‚   â”‚   â””â”€â”€ ChatAtom.ts        # Chat state
â”‚   â”œâ”€â”€ types/                 # TypeScript types
â”‚   â”‚   â””â”€â”€ chat.ts            # Chat message types
â”‚   â””â”€â”€ styles/                # Global styles
â”‚       â””â”€â”€ globals.css        # Tailwind CSS
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ model/PTIT_Ami/        # Live2D Model Assets
â”‚   â”‚   â”œâ”€â”€ Expressions/       # 16 expression files
â”‚   â”‚   â”œâ”€â”€ Motions/           # 11 motion groups
â”‚   â”‚   â””â”€â”€ PTIT_SDK.*         # Model files
â”‚   â”œâ”€â”€ live2dcubismcore.min.js # Live2D Core
â”‚   â””â”€â”€ *.avif                 # Background images
â”œâ”€â”€ static/                    # Static assets
â””â”€â”€ README.md
```

## ğŸ® Interactive Features

### Live2D Model Controls

**Mouse/Touch Interactions:**
- **Single Click**: General interaction with random responses
- **Double Click**: Special area-specific interactions
- **Drag**: Move the model around
- **Scroll/Pinch**: Zoom in/out
- **Hover**: Eye tracking follows cursor

**Keyboard Shortcuts:**
- `1, 2, 3`: Greeting motions
- `h`: Heart motion
- `n`: Head nod
- `s`: Head shake
- `p`: Hair stroking
- `f`: Face interaction
- `u`: Upper body interaction
- `b`: Body interaction
- `r`: Reset to default

**Hitbox Areas:**
- **Hair**: Gentle stroking â†’ Blush expressions
- **Face**: Friendly touches â†’ Cute expressions
- **Head**: General patting â†’ Happy responses
- **Upper Body**: Shoulder area â†’ Wave motions
- **Body**: Waist area â†’ Special interactions

### Chat Features

**AI Personality:**
- **Character**: Ami, a friendly PTIT student
- **Language**: Vietnamese with English support
- **Tone**: Warm, empathetic, and supportive
- **Response Length**: 4-6 sentences, concise and engaging

**Sentiment Analysis:**
- **Happy**: Excited expressions and motions
- **Sad**: Comforting responses with gentle animations
- **Love**: Heart expressions and special motions
- **Angry**: Understanding responses with calming animations

## ğŸ› ï¸ Development

### Available Scripts

```bash
# Development
pnpm dev          # Start development server
pnpm build        # Build for production
pnpm start        # Start production server

# Code Quality
pnpm lint         # Run Biome linter
pnpm format       # Format code with Biome
```

### Tech Stack

- **Framework**: Next.js 14.2.32 (App Router)
- **Language**: TypeScript 5.9.2
- **Styling**: Tailwind CSS 3.4.17
- **State Management**: Jotai 2.14.0
- **Live2D**: PIXI.js 6.5.10 + pixi-live2d-display 0.4.0
- **AI**: Google Generative AI 0.24.1
- **Voice**: ElevenLabs 2.15.0
- **Package Manager**: pnpm 9.2.0

## ğŸ¨ Customization

### Adding New Expressions
1. Add expression files to `public/model/PTIT_Ami/Expressions/`
2. Update `EXPRESSIONS` object in `Model.tsx`
3. Add sentiment analysis keywords if needed

### Adding New Motions
1. Add motion files to `public/model/PTIT_Ami/Motions/`
2. Update `MOTIONS` object in `Model.tsx`
3. Configure hitbox responses in `MOTION_GROUPS`

### Customizing AI Personality
Edit the `createSystemMessage` function in `src/app/api/chat/route.ts` to modify:
- Character personality
- Response style
- Language preferences
- Conversation rules

## ğŸ“± Embedding

### Basic Widget Embed
```html
<iframe 
  src="http://localhost:3000/widget?theme=default&size=medium"
  width="400" 
  height="500"
  frameborder="0">
</iframe>
```

### Advanced Integration
```javascript
// Load the widget script
const script = document.createElement('script');
script.src = '/embed.js';
document.head.appendChild(script);

// Initialize widget
window.WaifuWidget.init({
  theme: 'dark',
  size: 'large',
  position: 'bottom-right'
});
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Original Inspiration**: [wAIfu](https://github.com/unteifu/wAIfu) - The original waifu AI project
- **Live2D Technology**: Live2D Cubism SDK for character animation
- **PTIT Ami Model**: Custom Live2D model created for this project
- **Google Gemini**: Advanced AI conversation capabilities
- **ElevenLabs**: High-quality voice synthesis

## Credits to the [original repo](https://github.com/unteifu/wAIfu) 
